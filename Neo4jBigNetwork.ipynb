{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "# pip install py2neo\n",
    "from py2neo import Graph,Node,Relationship,PropertyDict,Subgraph,NodeMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare inputs: Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List #1: list of dictionary: list of news. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大的list是由很多的dictionary组成的\n",
    "# 每个dictionary是news的信息\n",
    "\n",
    "# 用来建立News Node(NewsName,Date,Newspaper,#NewsIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_news_topic = pd.read_pickle(\"list1_news.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_news_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List #2: list of list of dictionary: list of news, list of topic and news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大的list是由很多list组成的，\n",
    "# 每一个list是一个news，这个list是由很多dictionary组成的，每个dictionary是这个news包含的topic,\n",
    "# 不光包括一个model的topic，包括所有model的topic\n",
    "# 比如topic10_1,topic30_5\n",
    "# 顺序是model从少到多，index从小到大\n",
    "\n",
    "# 用来建立 Topic Node(Model,TopicIndex,TopicName)\n",
    "# 用来建立 News_Covers_Topic Relationship（TopicProportion）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic data from LJY's file\n",
    "list_news_topic = pd.read_pickle(\"list2_doc_topic_list.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_news_topic[0] # news1包含的所有的topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List #3: list of list of dictionary: list of topic, list of topic and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大的list是由很多的list组成的\n",
    "# 每个list是一个topic的信息，由很多dictionary组成的\n",
    "# topics的顺序是model从少到多，index从小到大\n",
    "# 每个dictionary是一个topic中的某一个word的的信息，包括wordname，wordtype\n",
    "# 还有wordweight用来建立topic和word之间的relationship\n",
    "\n",
    "# 用来建立 Word Node（WordName,WordType）\n",
    "# 用来建立 Topics_Contains_Word Relationship(WordWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topic_word =  pd.read_pickle('list3_topic_word_list.pickle')\n",
    "#list_topic_word[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List #4: list of topic: list of topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大的list是由很多的dictionary组成的\n",
    "# 每个dictionary是一个topic的信息，包括model，topicsname，topicindex\n",
    "# topics的顺序是model从少到多，index从小到大\n",
    "\n",
    "# 用来建立 Topic Node(Model,TopicIndex,TopicName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topic =  pd.read_pickle('list4_topic.pickle')\n",
    "#list_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List #5: list of list of dictionary: list of news, list of word in this news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大的list是由很多的list组成的\n",
    "# 每个list是一个news的信息，由很多dictionary组成的\n",
    "# 每个dictionary是一个news中的某一个word的的信息，包括wordname，wordtype\n",
    "\n",
    "# 用来建立 Word Node（WordName,WordType）\n",
    "# 用来建立 News_Has_Word Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_news_word =  pd.read_pickle('list5_news_word_list.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Spent:\n",
      "0:00:03.704862\n"
     ]
    }
   ],
   "source": [
    "g = Graph('http://localhost:7474',username='neo4j',password='test')\n",
    "g.delete_all()\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "tx = g.begin()\n",
    "\n",
    "### Build relationship 2: Topic contains word\n",
    "\n",
    "for i in range(len(list_topic)):\n",
    "    topic = list_topic[i]\n",
    "   # Build node of news\n",
    "    topic_node = Node(\"Topic\",**topic)\n",
    "    topic_node.__primarylabel__ = \"Topic\"\n",
    "    topic_node.__primarykey__ = \"TopicIndex\"\n",
    "    tx.merge(topic_node)\n",
    "    \n",
    "    for word in list_topic_word[i]:   \n",
    "        type_ = word['WordType']\n",
    "        weight = word['WordWeight']\n",
    "        # Build node of topic\n",
    "        word_node = Node(type_,WordName=word['WordName'])\n",
    "        word_node.__primarylabel__ = type_\n",
    "        word_node.__primarykey__ = \"WordName\" \n",
    "        tx.merge(word_node)\n",
    "        \n",
    "        # Build topic-word relationship\n",
    "        Topic_Word = Relationship.type(\"Topic_Contains_Word\")\n",
    "        tx.merge(Topic_Word(topic_node,word_node,WordWeight=str(weight)))\n",
    "\n",
    "### Build relationship 1&3: \n",
    "\n",
    "for i in range(len(list_news)):\n",
    "    news = list_news[i]\n",
    "   # Build node of news\n",
    "    news_node = Node(\"News\",**news)\n",
    "    news_node.__primarylabel__ = \"News\"\n",
    "    news_node.__primarykey__ = \"NewsName\"\n",
    "    tx.merge(news_node)\n",
    "       \n",
    "    ### Build Relationship 1: News covers topic\n",
    "    \n",
    "    for topic in list_news_topic[i]:   \n",
    "       \n",
    "        # Topic node: only remains attribute: Model,TopicIndex,TopicName\n",
    "        new_topic_node = dict(topic)\n",
    "        del(new_topic_node[('TopicProportion')])\n",
    "        \n",
    "        # Build node of topic\n",
    "        topic_node = Node('Topic',**new_topic_node)\n",
    "        topic_node.__primarylabel__ = 'Topic'\n",
    "        topic_node.__primarykey__ = \"TopicIndex\"    \n",
    "        tx.merge(topic_node)\n",
    "        \n",
    "        # Build topic-news relationship\n",
    "        Topic_News = Relationship.type(\"News_Covers_Topic\")\n",
    "        tx.merge(Topic_News(news_node,topic_node,\\\n",
    "                            TopicProportion=str(topic['TopicProportion'])))\n",
    "        \n",
    "    # Build Relationship 3 : News_Has_Word\n",
    "    \n",
    "    for word in list_news_word[i]:   \n",
    "       \n",
    "        # Build node of word\n",
    "        type_ = word['WordType']\n",
    "        word_node = Node(type_,WordName=word['WordName'])\n",
    "        word_node.__primarylabel__ = type_\n",
    "        word_node.__primarykey__ = \"WordName\"    \n",
    "        tx.merge(word_node)\n",
    "        \n",
    "        # Build word-news relationship\n",
    "        Word_News = Relationship.type(\"News_Has_Word\")\n",
    "        tx.merge(Word_News(news_node,word_node))\n",
    "           \n",
    "tx.commit() \n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print ('Time Spent:')\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查找某一个type\n",
    "g.nodes.match(\"university\").first()\n",
    "# 查找某一个type的数量\n",
    "len(g.nodes.match(\"university\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a.Model': 10,\n",
       "  'a.TopicIndex': '10_1',\n",
       "  'a.TopicName': '0.025*\"阿里巴巴\" + 0.017*\"京东\" + 0.013*\"腾讯\"'},\n",
       " {'a.Model': 10,\n",
       "  'a.TopicIndex': '10_2',\n",
       "  'a.TopicName': '0.019*\"现代\" + 0.012*\"奥巴马\" + 0.012*\"特朗普\"'}]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查找某个type的一些node\n",
    "g.run(\"MATCH (a:Topic) RETURN a.Model, a.TopicIndex,a.TopicName LIMIT 2\").data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a.TopicName': '0.025*\"阿里巴巴\" + 0.017*\"京东\" + 0.013*\"腾讯\"'},\n",
       " {'a.TopicName': '0.019*\"现代\" + 0.012*\"奥巴马\" + 0.012*\"特朗普\"'},\n",
       " {'a.TopicName': '0.014*\"国际会展中心\" + 0.007*\"公安部\" + 0.006*\"市工商局\"'},\n",
       " {'a.TopicName': '0.016*\"现代\" + 0.012*\"中国银行\" + 0.007*\"控股集团\"'},\n",
       " {'a.TopicName': '0.072*\"习近平\" + 0.039*\"联合国\" + 0.024*\"新华社\"'}]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据某个条件，查找某个type的一些node\n",
    "g.run(\"MATCH (a:Topic) WHERE a.Model={x} RETURN a.TopicName LIMIT 5\", x=10).data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
